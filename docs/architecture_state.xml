<system_architecture_doc>
  <metadata>
    <project_name>Auto-Evolving OSINT VLM Agent (SmartChrome)</project_name>
    <target_environment>Dell Alienware R16 (Local Execution, High VRAM/RAM)</target_environment>
    <host_application>Chromium (Custom Build)</host_application>
    <version>1.1.0</version>
    <purpose>Autonomous web navigation, OSINT brief generation, and self-improving behavior loop via human RLHF.</purpose>
  </metadata>

  <global_variables>
    <var name="MODEL_A" type="VLM" description="Frontend Actor. Embedded in Chrome via isolated process. Fast, responsive, vision-capable." target="Qwen3.5-35B-A3B (Quantized) OR Qwen3-VL" />
    <var name="MODEL_B" type="LLM" description="Backend Teacher/Analyst. Local background process." target="Qwen2.5-32B-Instruct OR DeepSeek-V3" />
    <var name="IPC_PROTOCOL" value="Chromium Mojo IPC (vlm_agent.mojom, vlm_renderer.mojom)" />
    <var name="INTERNAL_ROUTING" value="REST API Dispatcher (http://127.0.0.1:8000/vlm/act)" status="implemented" description="Now uses hardware-aware Python server (vlm_server.py)" />
    <var name="STORAGE" value="Local SQLite DB" />
  </global_variables>

  <modules>
    <module id="MOD_00_TEST_SUITE" status="implemented">
      <description>Automated verification suite for SmartChrome components.</description>
      <components>
        <component id="C_00A_CPP_UNIT_TESTS" status="implemented">
          <description>GTest suite for VLM components (Actuator, Observer, PageHost).</description>
          <tangible_implementation>vlm_agent_unittests (C++). Runs in Chromium build tree.</tangible_implementation>
        </component>
        <component id="C_00B_PYTHON_UNIT_TESTS" status="implemented">
          <description>Pytest suite for FastAPI backend and SQLite schemas.</description>
          <tangible_implementation>tests/test_vlm_server.py (Python). Verified via pytest.</tangible_implementation>
        </component>
        <component id="C_00C_SYSTEM_INTEGRATION_TEST" status="implemented">
          <description>End-to-End loop verification: Chrome -> Server -> Actuator -> DOM.</description>
          <tangible_implementation>scripts/test_e2e_integration.py. Uses Pyppeteer to verify physical interaction.</tangible_implementation>
        </component>
      </components>
    </module>
    <module id="MOD_01_FRONTEND_ENGINE" status="implemented">
      <description>Dual-state browser observer and actuator. Extracts WebContents state and executes UI commands.</description>
      <components>
        <component id="C_01_SENSOR_RENDERER_EXTRACTOR">
          <description>High-Level: Extracts DOM and Render events from the Blink process.</description>
          <tangible_implementation>
            Hooks into `DidMeaningfulLayout` inside `Blink`. Uses `base::SingleThreadTaskRunner::PostDelayedTask` to wait for clean layout cache, then walks `AXObjectCache` to extract a simplified Accessibility Tree with bounding boxes. Sends to Browser via `vlm_renderer.mojom` IPC.
          </tangible_implementation>
          <output format="json">{"a11y_tree": [...]}</output>
        </component>
        
        <component id="C_01B_SENSOR_BROWSER_PIVOT">
          <description>High-Level: Extracts clean OS-level Accessibility Tree directly from Browser process, bypassing Renderer complexity.</description>
          <tangible_implementation>
            Pivots to native extraction using `ui::AXNode` and `AXTreeSerializer` on the Browser side to gather accessibility states directly from the `WebContents` root, ensuring cross-process frame support.
          </tangible_implementation>
        </component>

        <component id="C_01C_SENSOR_AGGREGATOR">
          <description>High-Level: Takes visual viewport screenshot and aggregates sensory data.</description>
          <tangible_implementation>
            A `WebContentsObserver` inside the Browser Process. Triggers `RenderWidgetHostView::CopyFromSurface` to capture the full RGBA viewport bitmap when layout changes occur.
          </tangible_implementation>
          <output format="json">{"screenshot_rgba": "...", "a11y_tree_json": "..."}</output>
        </component>
        
        <component id="C_01D_NETWORK_DISPATCHER">
          <description>High-Level: Bridges internal Chromium C++ with Python ML Backend.</description>
          <tangible_implementation>
            Takes the aggregated Screenshot + A11y payload, constructs a JSON HTTP POST request, and dispatches it over the network to the Mock VLM Server (`http://127.0.0.1:8000/vlm/act`).
          </tangible_implementation>
        </component>

        <component id="C_02_ACTUATOR" status="implemented">
          <description>High-Level: Executes VLM logical actions on the browser.</description>
          <tangible_implementation>Implemented. Maps logical actions (`click`, `scroll`, `type`) and `target_bbox` dimensions from the VLM JSON response into native Chromium UI/Input Events via `VLMActuator`.</tangible_implementation>
          <input format="json">{"action": "click|scroll|type", "target_bbox": [x,y,w,h], "text": "..."}</input>
          <output>System-level execution within sandbox.</output>
        </component>
        
        <component id="C_03_VLM_UTILITY_PROCESS">
          <description>High-Level: Isolated sandbox process holding the VLM and managing modes.</description>
          <tangible_implementation>
            Launched via `ServiceProcessHost::Launch`. Communicates with Browser via `VLMObserver` Mojo interface (`vlm_agent.mojom`). Holds the state logic for SHADOW (Record) vs AUTONOMOUS (Act) modes.
          </tangible_implementation>
        </component>
      </components>
    </module>

    <module id="MOD_02_DATA_COLLECTION" status="implemented">
      <description>RLHF data pipeline via human intervention.</description>
      <components>
        <component id="C_04_INTERCEPTOR" status="implemented">
          <trigger>Hardware shortcut / Hotkey execution / Toolbar button</trigger>
          <process>Freeze MOD_01 AUTONOMOUS state. Capture immediate context. Toggle via VLMObserver.</process>
        </component>
        <component id="C_05_DELTA_LOGGER" status="implemented">
          <input>Context from C_04, VLM intended action, Human corrected action</input>
          <process>Create RLHF tuple. Log to SQLite via Python backend /vlm/rlhf_log.</process>
          <output destination="STORAGE">Tuple(State_Image, State_A11y, Bad_Action_VLM, Good_Action_Human)</output>
        </component>
      </components>
    </module>

    <module id="MOD_03_TEACHER_PIPELINE" status="implemented">
      <description>Asynchronous data synthesis using MODEL_B.</description>
      <components>
        <component id="C_06_COT_GENERATOR" status="implemented">
          <trigger>Cron job OR Queue threshold reached in STORAGE</trigger>
          <input>Tuple from C_05_DELTA_LOGGER</input>
          <process>Polls SQLite via teacher_worker.py. Prompt MODEL_B (Teacher LLM) to infer "Why was Bad_Action wrong and Good_Action right?". Generate Chain of Thought (CoT).</process>
          <output>Enriched training data with logical reasoning.</output>
        </component>
        <component id="C_07_DATA_FORMATTER" status="implemented">
          <input>Output from C_06</input>
          <process>Convert to VLM SFT/DPO standard JSONL format.</process>
          <output destination="STORAGE">training_dataset.jsonl</output>
        </component>
        <component id="C_08_OSINT_ANALYZER" status="implemented">
          <input>Raw text/data scraped by MODEL_A during AUTONOMOUS mode</input>
          <process>MODEL_B (Teacher LLM) deduplicates, analyzes, and formats via /osint/analyze endpoint.</process>
          <output format="markdown">Final OSINT Brief saved in backend/reports/.</output>
        </component>
      </components>
    </module>

    <module id="MOD_04_EVOLUTION_LOOP" status="implemented">
      <description>Local LoRA fine-tuning and weight updating.</description>
      <components>
        <component id="C_09_LOCAL_FORGE" status="implemented">
          <trigger>Nightly OR threshold = 50 entries in training_dataset.jsonl</trigger>
          <process>Execute QLoRA script (local_forge.py) on MODEL_A using generated dataset. Merge LoRA weights into base model.</process>
          <output>new_model_weights.gguf (or tflite/safetensors)</output>
        </component>
        <component id="C_10_HOT_RELOADER" status="implemented">
          <trigger>Successful completion of C_09</trigger>
          <process>Send RELOAD signal via POST /vlm/reload to vlm_server.py. Clears VRAM and reloads new weights.</process>
          <output>MODEL_A memory swap without Chromium restart.</output>
        </component>
      </components>
    </module>
  </modules>
</system_architecture_doc>
