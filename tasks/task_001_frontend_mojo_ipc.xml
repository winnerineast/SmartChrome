<gemini_cli_task>
  <context>
    We are building "SmartChrome", embedding a local Vision-Language Model (VLM) into Chromium. 
    You have two jobs in this task: 
    1. Save this task definition to the project tracking repository.
    2. Execute the actual C++ coding and compilation in the Chromium source repository.
  </context>

  <phase_1_project_management>
    <description>Save this prompt to the SmartChrome GitHub repo so we have a record of what we are doing.</description>
    <actions>
      <action>Ensure directory `~/SmartChrome/tasks/` exists.</action>
      <action>Save this entire XML prompt text into a new file located at: `~/SmartChrome/tasks/task_001_mojo_ipc.xml`</action>
      <action>Change directory to `~/SmartChrome`.</action>
      <action>Execute: `git add tasks/task_001_mojo_ipc.xml`</action>
      <action>Execute: `git commit -m "task: add mojo ipc interface definition prompt"`</action>
      <action>Execute: `git push`</action>
    </actions>
  </phase_1_project_management>

  <phase_2_chromium_execution>
    <description>Implement the IPC bridge between the main Browser Process and our isolated VLM Utility Process.</description>
    <actions>
      <action>Change directory to your Chromium source tree (e.g., `~/chromium/src`).</action>
      <action>Create a new file exactly at `components/vlm_agent/public/mojom/vlm_agent.mojom` with the following content:</action>
      
      <file_content path="components/vlm_agent/public/mojom/vlm_agent.mojom">
module vlm_agent.mojom;

import "mojo/public/mojom/base/big_buffer.mojom";

// The core interface for communicating with the embedded VLM process.
interface VLMObserver {
  // Sends the current viewport and accessibility tree to the VLM.
  // Returns a JSON string containing the VLM's decided action (e.g., click, scroll).
  OnPageStateCaptured(
      mojo_base.mojom.BigBuffer screenshot_rgba, 
      string a11y_tree_json) => (string action_response);

  // Used for the RLHF (Reinforcement Learning from Human Feedback) loop.
  // Reports when a human intercepts and corrects a bad VLM action.
  ReportHumanCorrection(
      string state_id, 
      string bad_action_json, 
      string good_action_json);
};
      </file_content>

      <action>Execute the build command: `autoninja -C out/Default components/vlm_agent`</action>
    </actions>
  </phase_2_chromium_execution>

  <execution_directive>
    Execute Phase 1 first to secure the task record. Then execute Phase 2. 
    Report back when both the GitHub push is successful and the autoninja build completes. Show the final exit code of the build.
  </execution_directive>
</gemini_cli_task>
