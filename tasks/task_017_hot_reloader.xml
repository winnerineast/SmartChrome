<gemini_cli_task>
  <context>
    We are building "SmartChrome", an Auto-Evolving OSINT VLM Agent.
    This task focuses on Phase 7: The Hot Reloader (`C_10_HOT_RELOADER`).
    Once `local_forge.py` (Task 016) finishes compiling the new weights, it needs to deploy them to the running `vlm_server.py`. We need to add a switch to seamlessly inject the smarter "Brain" into the live VLM server without forcing the user to restart their entire Chromium browsing session.
  </context>

  <phase_1_project_management>
    <description>Save this prompt to the SmartChrome GitHub repo.</description>
    <actions>
      <action>Save this XML to: `~/SmartChrome/tasks/task_017_hot_reloader.xml`</action>
      <action>Execute: `git add tasks/task_017_hot_reloader.xml`</action>
      <action>Execute: `git commit -m "task: add hot reloader prompt"`</action>
      <action>Execute: `git push`</action>
    </actions>
  </phase_1_project_management>

  <phase_2_python_backend>
    <description>Implement the Hot Reload functionality.</description>
    <actions>
      <action>Change directory to `~/SmartChrome/backend`.</action>
      <action>Modify `vlm_server.py`.</action>
      <action>Add a new FastAPI endpoint: `POST /vlm/reload`.</action>
      <action>The endpoint accepts JSON: `{ "new_model_path": "..." }`.</action>
      <action>When hit, gracefully free the current global model memory buffers:
          - If MLX: Dereference the model and rely on Python garbage collection or `mlx.core.eval()`.
          - If vLLM/CUDA: `del model; torch.cuda.empty_cache(); gc.collect()`.
      </action>
      <action>Load the path provided in `new_model_path` (e.g., `SmartChrome-v2.gguf` or internal safetensors) back into the global model variable so the next `POST /vlm/act` request utilizes the new tuned weights.</action>
      <action>Modify `local_forge.py` from Task 016: Once the `.gguf` (CUDA) or `.safetensors` (MLX) is saved to disk perfectly, fire a synchronous HTTP POST from within that script to `http://127.0.0.1:8000/vlm/reload` with the new file path to trigger the swap automatically.</action>
    </actions>
  </phase_2_python_backend>

  <execution_directive>
    Execute Phase 1 to capture the intent. Phase 2 requires careful global state management in Python to prevent VRAM memory leaks during the hot swap.
  </execution_directive>
</gemini_cli_task>
